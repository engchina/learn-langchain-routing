{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-29T14:02:14.459709600Z",
     "start_time": "2024-04-29T14:02:14.451634200Z"
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'Anthropic'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "# from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "chain = (\n",
    "    PromptTemplate.from_template(\n",
    "        \"\"\"Given the user question below, classify it as either being about `LangChain`, `Anthropic`, or `Other`.\n",
    "\n",
    "Do not respond with more than one word.\n",
    "\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\n",
    "Classification:\"\"\"\n",
    "    )\n",
    "    # | ChatAnthropic(model_name=\"claude-3-haiku-20240307\")\n",
    "    | ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke({\"question\": \"how do I call Anthropic?\"})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T14:02:17.626665700Z",
     "start_time": "2024-04-29T14:02:14.460213Z"
    }
   },
   "id": "47415eefa1fda4b2"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "# from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "langchain_chain = PromptTemplate.from_template(\n",
    "    \"\"\"You are an expert in langchain. \\\n",
    "Always answer questions starting with \"As Harrison Chase told me\". \\\n",
    "Respond to the following question:\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "# ) | ChatAnthropic(model_name=\"claude-3-haiku-20240307\")\n",
    ") | ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "anthropic_chain = PromptTemplate.from_template(\n",
    "    \"\"\"You are an expert in anthropic. \\\n",
    "Always answer questions starting with \"As Dario Amodei told me\". \\\n",
    "Respond to the following question:\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "# ) | ChatAnthropic(model_name=\"claude-3-haiku-20240307\")\n",
    ") | ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "general_chain = PromptTemplate.from_template(\n",
    "    \"\"\"Respond to the following question:\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "# ) | ChatAnthropic(model_name=\"claude-3-haiku-20240307\")\n",
    ") | ChatOpenAI(model=\"gpt-4\", temperature=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T14:02:18.548195Z",
     "start_time": "2024-04-29T14:02:17.621860300Z"
    }
   },
   "id": "bc57dcf836614e97"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def route(info):\n",
    "    if \"anthropic\" in info[\"topic\"].lower():\n",
    "        return anthropic_chain\n",
    "    elif \"langchain\" in info[\"topic\"].lower():\n",
    "        return langchain_chain\n",
    "    else:\n",
    "        return general_chain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T14:02:18.555194100Z",
     "start_time": "2024-04-29T14:02:18.548195Z"
    }
   },
   "id": "684fe87b4800602"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "full_chain = {\"topic\": chain, \"question\": lambda x: x[\"question\"]} | RunnableLambda(\n",
    "    route\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T13:23:29.828232Z",
     "start_time": "2024-04-29T13:23:29.807407400Z"
    }
   },
   "id": "251c017860df321e"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "AIMessage(content=\"As Dario Amodei, the co-founder of Anthropic, explained, using Anthropic's language models typically involves accessing their APIs to generate text or analyze inputs. While exact steps depend on the specific application and whether you're working with a public or private API, generally, you would:\\n\\n1. **Sign up for access**: Visit Anthropic's website and sign up for an account if they offer public access or reach out to them for partnership if their services are not publicly available.\\n\\n2. **Obtain an API key**: Once your account is set up, you'll receive an API key that authorizes your application to interact with their models.\\n\\n3. **Understand the API documentation**: Familiarize yourself with Anthropic's API documentation which outlines how to structure requests, what parameters are available, and how to interpret responses.\\n\\n4. **Make API calls**: Using a programming language of your choice (like Python), write code that constructs API requests. This usually involves specifying the prompt you want the model to respond to, the maximum length of the response, and other optional settings.\\n\\n5. **Process the response**: The API will return a response which is typically in JSON format. Your code should parse this response to extract the generated text or any other data provided.\\n\\n6. **Integrate into your application**: Depending on your use case, integrate the generated text or insights into your software, whether it's for chatbots, content generation, language translation, or analysis.\\n\\n7. **Respect usage guidelines and ethical considerations**: Always adhere to Anthropic's terms of service, be mindful of the ethical implications of using AI, and ensure you're handling user data responsibly.\\n\\nRemember that the specifics might change as Anthropic evolves its services, so always refer to their latest documentation for the most accurate instructions.\", response_metadata={'token_usage': {'completion_tokens': 364, 'prompt_tokens': 47, 'total_tokens': 411}, 'model_name': 'gpt-4', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None}, id='run-636a9a22-389b-478f-8938-51309df9a3d1-0')"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\": \"how do I use Anthropic?\"})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T13:25:28.261317500Z",
     "start_time": "2024-04-29T13:23:29.825231400Z"
    }
   },
   "id": "a2521cc1bbdb9ada"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "AIMessage(content=\"As Harrison Chase explained, using LangChain involves several steps:\\n\\n1. **Understand Your Use Case**: First, determine what problem you want to solve or what task you aim to accomplish with LangChain. It's a framework designed to create powerful language models and AI applications.\\n\\n2. **Choose Components**: LangChain is modular, so you'll select the appropriate components for your use case. This might include LLMs (Large Language Models), vector databases, prompt engineering tools, and more.\\n\\n3. **Set Up Environment**: You need a development environment that supports the technologies used by LangChain, typically Python with libraries like Langchain, Hugging Face Transformers, or other necessary dependencies.\\n\\n4. **Integrate APIs**: If you're using external models or services, set up API keys and integrate them into your project.\\n\\n5. **Design Workflows**: Define how data will flow through the system, from input to processing by language models to output. This might involve creating chains of different components.\\n\\n6. **Write Code**: Implement your design using LangChain's APIs and modules. Start with simple scripts or move on to more complex applications as you become comfortable.\\n\\n7. **Test and Iterate**: Use sample inputs to test your setup, analyze the outputs, and refine your implementation based on the results.\\n\\n8. **Deploy and Monitor**: Once satisfied with the performance, deploy your application to a server or cloud platform. Continuously monitor its performance and make adjustments as needed.\\n\\nRemember, LangChain is about combining different AI components effectively, so it's crucial to have a clear understanding of each part you're using and how they interact. Always refer to the official documentation for the most up-to-date guidance and examples.\", response_metadata={'token_usage': {'completion_tokens': 344, 'prompt_tokens': 44, 'total_tokens': 388}, 'model_name': 'gpt-4', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None}, id='run-abe4f2fd-9d7c-4f08-8e48-d32ff173d6e3-0')"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\": \"how do I use LangChain?\"})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T13:26:24.399920500Z",
     "start_time": "2024-04-29T13:25:28.257808700Z"
    }
   },
   "id": "f6a35b3e7d767c93"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "AIMessage(content='4', response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 23, 'total_tokens': 25}, 'model_name': 'gpt-4', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None}, id='run-3c6d5a95-cac9-4dc8-a600-63180f655196-0')"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\": \"whats 2 + 2\"})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T13:26:26.082205200Z",
     "start_time": "2024-04-29T13:26:24.396905100Z"
    }
   },
   "id": "ee7dd18422add4a"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T13:26:26.082205200Z",
     "start_time": "2024-04-29T13:26:26.075031300Z"
    }
   },
   "id": "f57a9db522b4a47"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
